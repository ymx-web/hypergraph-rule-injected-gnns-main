"""
rule_mining_hyperedges.py
----------------------------------------
Automatic generation of Sourceâ€“Target (Sâ†’T) hyperedge rules
for n-ary KGs such as FB-AUTO, JF17K, WikiPeople.

Usage:
    python rule_mining_hyperedges.py
----------------------------------------
Author: Ziheng Yang (UCAS)
Date: 2025-ï¼—
"""

# import os
# import random
# from collections import defaultdict
# from itertools import combinations
#
# def mine_hyperedge_rules(dataset_path, output_path, min_conf=0.6, max_rules=200):
#     """
#     Automatically generate hyperedge-style rules (Sâ†’T)
#     from dataset train.txt file.
#
#     Each rule has format:
#         r1(A,B) âˆ§ r2(B,C) â†’ r3(A,C)   confidence
#     """
#     triples = []
#     train_file = os.path.join(dataset_path, "train.txt")
#     if not os.path.exists(train_file):
#         print(f"âš ï¸ No train.txt found in {dataset_path}, skip.")
#         return
#
#     # Load triples
#     with open(train_file, "r", encoding="utf-8") as f:
#         for line in f:
#             parts = line.strip().split("\t")
#             if len(parts) < 3:
#                 continue
#             h, r, t = parts[:3]
#             triples.append((h, r, t))
#
#     if len(triples) == 0:
#         print(f"âš ï¸ No valid triples found in {dataset_path}.")
#         return
#
#     # Co-occurrence mining
#     head_rules = defaultdict(lambda: defaultdict(int))
#     for (h1, r1, t1), (h2, r2, t2) in combinations(triples[:5000], 2):  # limit sample for speed
#         if t1 == h2:  # path composition
#             head_rules[(r1, r2, "path")]["count"] += 1
#         elif h1 == h2:  # shared head
#             head_rules[(r1, r2, "shared_head")]["count"] += 1
#         elif t1 == t2:  # shared tail
#             head_rules[(r1, r2, "shared_tail")]["count"] += 1
#
#     rules = []
#     for (r1, r2, typ), stat in head_rules.items():
#         conf = round(random.uniform(min_conf, 0.95), 2)
#         if typ == "path":
#             head = random.choice([r1, r2])
#             rule = f"{r1}(A,B) âˆ§ {r2}(B,C) â†’ {head}(A,C)\t{conf}"
#         elif typ == "shared_head":
#             head = random.choice([r1, r2])
#             rule = f"{r1}(A,B) âˆ§ {r2}(A,C) â†’ {head}(B,C)\t{conf}"
#         elif typ == "shared_tail":
#             head = random.choice([r1, r2])
#             rule = f"{r1}(A,B) âˆ§ {r2}(C,B) â†’ {head}(A,C)\t{conf}"
#         else:
#             continue
#         rules.append(rule)
#
#     random.shuffle(rules)
#     rules = rules[:max_rules]
#
#     os.makedirs(os.path.dirname(output_path), exist_ok=True)
#     with open(output_path, "w", encoding="utf-8") as f:
#         for r in rules:
#             f.write(r + "\n")
#
#     print(f"âœ… Mined {len(rules)} hyperedge rules for {dataset_path} â†’ {output_path}")
#
#
# def main():
#     data_root = "data"
#     if not os.path.exists(data_root):
#         print("âŒ data/ directory not found. Please place this script in the project root.")
#         return
#
#     datasets = [
#         "FB-AUTO",
#         "JF17K",
#         "JF17K-3",
#         "JF17K-4",
#         "WikiPeople",
#         "WikiPeople-3",
#         "WikiPeople-4",
#     ]
#
#     for d in datasets:
#         path = os.path.join(data_root, d)
#         output = os.path.join(path, "rules_hyperedges.txt")
#         mine_hyperedge_rules(path, output)
#
#     print("\nğŸ¯ All done. Rules generated under each dataset folder!")
#
#
# if __name__ == "__main__":
#     main()
import argparse
from collections import defaultdict, Counter
import itertools
import math
import os

def parse_args():
    ap = argparse.ArgumentParser("Role-aware path rule miner (v6): r1âˆ˜r2=>r3 with arg joins + PCA conf")
    ap.add_argument("--train_path", required=True, help="tab file: rel \\t arg1 \\t arg2 ...")
    ap.add_argument("--out_path", required=True, help="rules output txt")
    ap.add_argument("--min_support", type=int, default=2)
    ap.add_argument("--min_conf", type=float, default=0.05)
    ap.add_argument("--topk", type=int, default=200)
    ap.add_argument("--target_head", type=str, default=None, help="only keep rules ending with this head relation")
    ap.add_argument("--enable_3hop", action="store_true")
    ap.add_argument("--verbose", action="store_true")
    return ap.parse_args()

def load_facts(path):
    rel2facts = defaultdict(list)
    with open(path, "r", encoding="utf-8") as f:
        for ln in f:
            parts = ln.strip().split("\t")
            if len(parts) < 3:  # rel + >=2 args
                continue
            rel, args = parts[0], parts[1:]
            rel2facts[rel].append(tuple(args))
    return rel2facts

def build_indexes(rel2facts):
    """
    ä¸ºæ¯ä¸ªå…³ç³»å»ºç«‹ï¼š
      - role2ents[role_idx] -> set(entities)
      - pair2count[(role_i_entity, role_j_entity, i, j)] -> countï¼ˆå¿«é€Ÿä½“é‡ç»Ÿè®¡ï¼‰
    ä»¥åŠå…¨å±€ (ent -> positions) åå‘ç´¢å¼•ï¼Œä¾¿äº join
    """
    rel2_role2ents = {}
    rel2_pairs_anypos = {}
    ent2pos = defaultdict(list)  # ent -> [(rel, role_idx)]
    for r, facts in rel2facts.items():
        max_len = max(len(f) for f in facts)
        role2ents = [set() for _ in range(max_len)]
        pairs_anypos = Counter()
        for f in facts:
            L = len(f)
            for i,e in enumerate(f):
                role2ents[i].add(e)
                ent2pos[e].append((r,i))
            # æ‰€æœ‰æˆå¯¹è§’è‰²ç»„åˆï¼ˆä»»æ„ä¸¤ä½ç½®ï¼‰
            for i,j in itertools.combinations(range(L), 2):
                pairs_anypos[(f[i], f[j], i, j)] += 1
        rel2_role2ents[r] = role2ents
        rel2_pairs_anypos[r] = pairs_anypos
    return rel2_role2ents, rel2_pairs_anypos, ent2pos

def entity_pair_in_rel(rel2facts, rel, a, b):
    """æ£€æŸ¥åœ¨å…³ç³» rel çš„ä»»æ„ä¸¤ä¸ªè§’è‰²ä½ç½®æ˜¯å¦å­˜åœ¨åŒä¸€äº‹å®ä½¿ (a,b) åŒæ—¶å‡ºç°ï¼ˆå…è®¸é¡ºåºä»»æ„ï¼‰"""
    # é€Ÿåº¦æƒè¡¡ï¼šç®€å•éå†ï¼›å¦‚éœ€åŠ é€Ÿå¯ä¸ºæ¯ä¸ªrelå»º entity->fact ids map
    for f in rel2facts[rel]:
        if a in f and b in f:
            return True
    return False

def enumerate_2hop_rules(rel2facts, rel2_role2ents, ent2pos, min_support, min_conf, target_head, verbose):
    """
    æ¨¡æ¿ï¼šr1(s, â€¦, j) âˆ§ r2(j', â€¦, t) => r3(s, â€¦, t)
    åšæ³•ï¼š
      1) æšä¸¾ r1,r2ï¼›å¯¹ r1 çš„æ¯ä¸ªè§’è‰² j ä¸ r2 çš„æ¯ä¸ªè§’è‰² j' åš joinï¼ˆåŒä¸€å®ä½“å‡ºç°ï¼‰
      2) å– r1 çš„æºä½ s âˆˆ roles(r1)ï¼Œr2 çš„ç›®æ ‡ä½ t âˆˆ roles(r2)ï¼Œå½¢æˆ candidate (a_s, b_t)
      3) åœ¨æ‰€æœ‰ r3 ä¸­æ£€æŸ¥æ˜¯å¦å­˜åœ¨äº‹å®åŒ…å« (a_s, b_t) è¿™å¯¹å®ä½“ï¼ˆä»»æ„è§’è‰²å¯¹ï¼‰
      4) ç»Ÿè®¡ support/ conf / pca-conf
    """
    rules = []
    rels = list(rel2facts.keys())
    # é¢„å…ˆå»ºç«‹ å„relçš„role->entityé›†åˆï¼Œä¾¿äºç¬›å¡å°”ç§¯è¿‡æ»¤
    for r1, r2 in itertools.permutations(rels, 2):
        role2ents1 = rel2_role2ents[r1]
        role2ents2 = rel2_role2ents[r2]
        # æšä¸¾ join è§’è‰² (j from r1) ä¸ (j' from r2)
        for j in range(len(role2ents1)):
            for jp in range(len(role2ents2)):
                join_ents = role2ents1[j] & role2ents2[jp]
                if len(join_ents) < min_support:
                    continue
                # å¯¹ r1 é€‰ä¸€ä¸ªæºä½ s, å¯¹ r2 é€‰ä¸€ä¸ªç›®æ ‡ä½ tï¼ˆå¯ä¸ joinä½ä¸åŒï¼‰
                for s in range(len(role2ents1)):
                    if s == j:  # æºä½ä¸joinä½å¯ä»¥ä¸åŒï¼Œä¹Ÿå¯å…è®¸ç›¸åŒï¼›æ­¤å¤„å…è®¸ç›¸åŒä¼šäº§ç”Ÿæ›´å¤šåŒ¹é…ï¼ŒæŒ‰éœ€åˆ‡æ¢
                        pass
                    for t in range(len(role2ents2)):
                        # æ„é€  (a_s, b_t) å€™é€‰å¯¹ï¼šéœ€è¦ä»äº‹å®çº§ç»Ÿè®¡ï¼Œé¿å…ä»…ç”¨é›†åˆè¿‘ä¼¼
                        # éå†å®ä½“ join_entsï¼Œé€šè¿‡ ent2pos æ‰¾åˆ°å…·ä½“äº‹å®ç»„åˆ
                        pair_counts = Counter()  # (a, b) -> count
                        body_support = 0
                        # éå†å‡ºç°äº r1@j ä¸ r2@jp çš„åŒä¸€å®ä½“ e
                        for e in join_ents:
                            # æ‰¾åˆ° e åœ¨ r1 çš„æ‰€æœ‰äº‹å®ä½ç½®
                            r1_pos = [(rr, idx) for (rr, idx) in ent2pos[e] if rr == r1 and idx == j]
                            r2_pos = [(rr, idx) for (rr, idx) in ent2pos[e] if rr == r2 and idx == jp]
                            if not r1_pos or not r2_pos:
                                continue
                            # éå† r1 çš„æ‰€æœ‰äº‹å®ï¼ŒæŠ½å–æºä½å®ä½“ a_s
                            for f1 in rel2facts[r1]:
                                if len(f1) <= max(j, s):
                                    continue
                                if f1[j] != e:
                                    continue
                                a = f1[s]
                                # éå† r2 çš„æ‰€æœ‰äº‹å®ï¼ŒæŠ½å–ç›®æ ‡ä½å®ä½“ b_t
                                for f2 in rel2facts[r2]:
                                    if len(f2) <= max(jp, t):
                                        continue
                                    if f2[jp] != e:
                                        continue
                                    b = f2[t]
                                    pair_counts[(a,b)] += 1
                                    body_support += 1
                        if body_support < min_support:
                            continue
                        # å¯»æ‰¾ head r3 ä½¿ (a,b) å…±ç°
                        for r3 in rels:
                            if r3 == r1 or r3 == r2:
                                continue  # å»è‡ªå¾ªç¯
                            head_hits = 0
                            # åœ¨ r3 çš„äº‹å®ä¸­éªŒè¯ (a,b) å…±åŒå‡ºç°ï¼ˆä»»æ„è§’è‰²å¯¹ï¼‰
                            for (a,b), c in pair_counts.items():
                                if entity_pair_in_rel(rel2facts, r3, a, b):
                                    head_hits += c
                            if head_hits < min_support:
                                continue
                            # è®¡ç®— conf / pca-conf / lift
                            conf = head_hits / (body_support + 1e-9)
                            if conf < min_conf:
                                continue
                            # PCA-confidence è¿‘ä¼¼ï¼šç”¨ r1åœ¨sä½çš„å®ä½“å¯ä¸ä»»æ„r2çš„tä½å®ä½“ç»„åˆä½œä¸ºåˆ†æ¯
                            denom_pca = 0
                            for e in role2ents1[s]:
                                # è¯¥ e ä½œä¸ºæºä½ï¼Œèƒ½ä¸å¤šå°‘ r2@t çš„å®ä½“é…å¯¹ï¼Ÿ
                                denom_pca += len(role2ents2[t])
                            pca_conf = head_hits / (denom_pca + 1e-9)

                            score = conf * (1 + math.log(1 + pca_conf*10.0))
                            rules.append({
                                "r1": r1, "r2": r2, "r3": r3,
                                "s": s, "j": j, "jp": jp, "t": t,
                                "support": head_hits, "body": body_support,
                                "conf": round(conf, 4),
                                "pca": round(pca_conf, 6),
                                "score": round(score, 4)
                            })
                            if verbose:
                                print(f"[2hop] {r1}[{s}] & {r2}[{t}] via join {j}-{jp} -> {r3} | supp={head_hits} conf={conf:.3f} pca={pca_conf:.3e} score={score:.3f}")
    # å»é‡ï¼šåŒä¸€ (r1,r2,r3,s,j,jp,t) ä¿ç•™æœ€é«˜åˆ†
    uniq = {}
    for R in rules:
        key = (R["r1"], R["r2"], R["r3"], R["s"], R["j"], R["jp"], R["t"])
        if key not in uniq or R["score"] > uniq[key]["score"]:
            uniq[key] = R
    rules = sorted(uniq.values(), key=lambda x: -x["score"])
    # ç›®æ ‡å…³ç³»è¿‡æ»¤
    if target_head:
        rules = [R for R in rules if R["r3"] == target_head]
    return rules

def save_rules(rules, out_path, topk=200):
    os.makedirs(os.path.dirname(out_path), exist_ok=True)
    with open(out_path, "w", encoding="utf-8") as f:
        f.write("# === Role-aware 2-hop rules: r1(arg_s, â€¦, arg_j) âˆ§ r2(arg_j', â€¦, arg_t) â†’ r3(arg_s, â€¦, arg_t)\n")
        for R in rules[:topk]:
            f.write(
                f"{R['r1']}[arg{R['s']}] & {R['r2']}[arg{R['t']}] "
                f"via join {R['r1']}[arg{R['j']}]={R['r2']}[arg{R['jp']}] "
                f"=> {R['r3']}(arg{R['s']}, arg{R['t']}) "
                f"support={R['support']} body={R['body']} conf={R['conf']} pca={R['pca']} score={R['score']}\n"
            )
    print(f"âœ… Saved {min(len(rules), topk)} rules to {out_path}")

def main():
    args = parse_args()
    rel2facts = load_facts(args.train_path)
    print(f"Loaded {len(rel2facts)} relations from {args.train_path}")
    rel2_role2ents, rel2_pairs_anypos, ent2pos = build_indexes(rel2facts)
    rules = enumerate_2hop_rules(
        rel2facts, rel2_role2ents, ent2pos,
        min_support=args.min_support,
        min_conf=args.min_conf,
        target_head=args.target_head,
        verbose=args.verbose,
    )
    save_rules(rules, args.out_path, args.topk)

if __name__ == "__main__":
    main()
